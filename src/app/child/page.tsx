'use client'

import { useState, useEffect, useRef, useCallback } from 'react'

export default function ChildPage() {
  const [isProcessing, setIsProcessing] = useState(false)
  const [response, setResponse] = useState('')
  const [lastHeard, setLastHeard] = useState('')
  const [status, setStatus] = useState('ì‹œì‘ ì¤‘...')
  const recognitionRef = useRef<any>(null)
  const isProcessingRef = useRef(false)
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null)
  const lastFinalRef = useRef('')

  // TTS + ëë‚˜ë©´ ì½œë°±
  const speak = useCallback((text: string, onEnd?: () => void) => {
    if (typeof window === 'undefined') return
    
    window.speechSynthesis.cancel()
    
    const utterance = new SpeechSynthesisUtterance(text)
    utterance.lang = 'ko-KR'
    utterance.rate = 0.9
    utterance.pitch = 1.2
    utterance.volume = 1.0

    const voices = window.speechSynthesis.getVoices()
    const koVoice = voices.find(v => v.lang.includes('ko'))
    if (koVoice) utterance.voice = koVoice

    utterance.onend = () => {
      console.log('[TTS ë]')
      if (onEnd) onEnd()
    }

    utterance.onerror = () => {
      console.log('[TTS ì—ëŸ¬]')
      if (onEnd) onEnd()
    }

    window.speechSynthesis.speak(utterance)
  }, [])

  // ìŒì„± ì¸ì‹ ì‹œì‘
  const startListening = useCallback(() => {
    if (recognitionRef.current && !isProcessingRef.current) {
      try {
        recognitionRef.current.start()
        setStatus('ğŸ¤ ë“£ê³  ìˆì–´ìš”')
        console.log('[ë“£ê¸° ì‹œì‘]')
      } catch (e) {
        // ì´ë¯¸ ì‹œì‘ë¨
      }
    }
  }, [])

  // ìŒì„± ì¸ì‹ ì¤‘ì§€
  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
        console.log('[ë“£ê¸° ì¤‘ì§€]')
      } catch (e) {}
    }
  }, [])

  // API í˜¸ì¶œ
  const callAPI = useCallback(async (text: string) => {
    if (isProcessingRef.current || !text.trim()) return
    
    isProcessingRef.current = true
    setIsProcessing(true)
    setStatus('ğŸ’­ ìƒê° ì¤‘...')
    
    // ë“£ê¸° ì¤‘ì§€ (TTS ì†Œë¦¬ ì•ˆ ë“£ë„ë¡)
    stopListening()

    try {
      const res = await fetch('/api/talk', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: text.trim() }),
      })

      const data = await res.json()
      const message = data.ok ? data.message : 'ë‹¤ì‹œ ë§í•´ì¤„ë˜?'
      
      setResponse(message)
      setIsProcessing(false)
      setStatus('ğŸ”Š ë§í•˜ëŠ” ì¤‘...')
      
      // TTS ì¬ìƒ, ëë‚˜ë©´ ë‹¤ì‹œ ë“£ê¸° ì‹œì‘
      speak(message, () => {
        isProcessingRef.current = false
        lastFinalRef.current = ''
        setLastHeard('')
        startListening()
      })

    } catch (error) {
      console.error('API ì˜¤ë¥˜:', error)
      setResponse('ì ê¹, ë‹¤ì‹œ í•´ë³¼ê¹Œ?')
      setIsProcessing(false)
      isProcessingRef.current = false
      startListening()
    }
  }, [speak, stopListening, startListening])

  // í…ìŠ¤íŠ¸ì—ì„œ ì›¨ì´í¬ ì›Œë“œ ì œê±°
  const cleanText = (text: string): string => {
    const patterns = ['ì•„ì´ì•¼', 'ì•„ì´ì–Œ', 'ì•„ì´ì•„', 'ì•„ì´ì—¬', 'ì• ì•¼', 'ì´ì•¼', 'ì•„ì•¼']
    let result = text
    for (const p of patterns) {
      result = result.replace(new RegExp(p, 'gi'), '').trim()
    }
    return result || text
  }

  useEffect(() => {
    const SpeechRecognition =
      (window as any).SpeechRecognition ||
      (window as any).webkitSpeechRecognition

    if (!SpeechRecognition) {
      setStatus('âŒ ìŒì„± ì¸ì‹ ë¯¸ì§€ì›')
      return
    }

    // TTS ìŒì„± ë¡œë“œ
    window.speechSynthesis.getVoices()
    window.speechSynthesis.onvoiceschanged = () => {
      window.speechSynthesis.getVoices()
    }

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = 'ko-KR'

    recognitionRef.current = recognition

    recognition.onresult = (event: any) => {
      if (isProcessingRef.current) return  // ì²˜ë¦¬ ì¤‘ì´ë©´ ë¬´ì‹œ
      
      let finalTranscript = ''
      let interimTranscript = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
          finalTranscript += transcript
        } else {
          interimTranscript += transcript
        }
      }

      const currentText = finalTranscript || interimTranscript
      if (currentText) {
        setLastHeard(currentText)
      }

      if (finalTranscript) {
        lastFinalRef.current = finalTranscript
        
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current)
        }
        
        // 1ì´ˆ í›„ API í˜¸ì¶œ
        silenceTimerRef.current = setTimeout(() => {
          if (lastFinalRef.current && !isProcessingRef.current) {
            const cleaned = cleanText(lastFinalRef.current)
            console.log('[API í˜¸ì¶œ]', cleaned)
            callAPI(cleaned)
          }
        }, 1000)
      }
    }

    recognition.onerror = (event: any) => {
      console.log('[ì˜¤ë¥˜]', event.error)
      if (event.error === 'not-allowed') {
        setStatus('ğŸ”’ ë§ˆì´í¬ ê¶Œí•œ í•„ìš”')
        return
      }
      if (!isProcessingRef.current) {
        setTimeout(startListening, 1000)
      }
    }

    recognition.onend = () => {
      console.log('[ì¸ì‹ ì¢…ë£Œ]')
      // ì²˜ë¦¬ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì¬ì‹œì‘
      if (!isProcessingRef.current) {
        setTimeout(startListening, 300)
      }
    }

    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
    navigator.mediaDevices.getUserMedia({ audio: true })
      .then(() => {
        recognition.start()
        setStatus('ğŸ¤ ë“£ê³  ìˆì–´ìš”')
      })
      .catch((err) => {
        console.error('[ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€]', err)
        setStatus('ğŸ”’ ë§ˆì´í¬ ê¶Œí•œ í•„ìš”')
      })

    return () => {
      if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current)
      try { recognition.stop() } catch (e) {}
    }
  }, [callAPI, startListening])

  return (
    <main className="flex flex-col items-center justify-center min-h-screen p-4 bg-gradient-to-b from-pink-200 via-purple-100 to-blue-200">
      <div className="text-center mb-6">
        <div className={`text-8xl mb-4 ${isProcessing ? 'animate-pulse' : 'animate-bounce'}`}>
          {isProcessing ? 'ğŸ¤”' : status.includes('ë§í•˜ëŠ”') ? 'ğŸ—£ï¸' : 'ğŸ¤'}
        </div>
        <h1 className="text-5xl font-bold text-purple-800 mb-3">ì•„ì´ì•¼!</h1>
        <p className="text-xl text-purple-600">ë­ë“  ë§í•´ë´!</p>
      </div>

      {lastHeard && !status.includes('ë§í•˜ëŠ”') && (
        <div className="mb-4 px-5 py-2 bg-white/60 rounded-full text-gray-700 text-lg max-w-xs text-center">
          ğŸ§ "{lastHeard}"
        </div>
      )}

      {response && (
        <div className="mt-2 p-6 bg-white rounded-3xl shadow-xl max-w-sm text-center">
          <p className="text-2xl text-gray-800 leading-relaxed font-bold">
            {response}
          </p>
        </div>
      )}

      {isProcessing && (
        <div className="mt-6">
          <div className="animate-spin rounded-full h-14 w-14 border-4 border-purple-300 border-t-purple-600"></div>
        </div>
      )}

      <div className="fixed bottom-4 left-4 right-4 flex justify-center">
        <div className={`px-5 py-2 rounded-full text-base font-semibold shadow-lg ${
          status.includes('ìƒê°') ? 'bg-yellow-400 text-gray-800' :
          status.includes('ë§í•˜ëŠ”') ? 'bg-blue-500 text-white' :
          status.includes('ë“£ê³ ') ? 'bg-green-500 text-white' :
          'bg-red-400 text-white'
        }`}>
          {status}
        </div>
      </div>
    </main>
  )
}
