'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import { speakText } from '@/components/AudioPlayer'

export default function ChildPage() {
  const [isProcessing, setIsProcessing] = useState(false)
  const [response, setResponse] = useState('')
  const [lastHeard, setLastHeard] = useState('')
  const recognitionRef = useRef<any>(null)
  const isProcessingRef = useRef(false)

  // API í˜¸ì¶œ
  const callAPI = useCallback(async (text: string) => {
    if (isProcessingRef.current) return
    isProcessingRef.current = true
    setIsProcessing(true)
    setResponse('')

    try {
      const res = await fetch('/api/talk', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: text.trim(),
          childId: 'default-child',
        }),
      })

      const data = await res.json()

      if (data.ok) {
        setResponse(data.message)
        speakText(data.message)
      } else {
        setResponse('ë‹¤ì‹œ ë§í•´ë³¼ê¹Œ?')
      }
    } catch (error) {
      console.error('API ì˜¤ë¥˜:', error)
      setResponse('ì—°ê²° ì˜¤ë¥˜! ë‹¤ì‹œ í•´ë³¼ê¹Œ?')
    } finally {
      setIsProcessing(false)
      isProcessingRef.current = false
    }
  }, [])

  // ì›¨ì´í¬ ì›Œë“œ ì²´í¬
  const checkWakeWord = useCallback((text: string): string | null => {
    const lower = text.toLowerCase().replace(/\s/g, '')
    const wakePatterns = [
      'ì•„ì´ì•¼', 'ì•„ì´ì–Œ', 'ì•„ì´ì•„', 'ì•„ì´ì—¬', 'ì• ì•¼', 
      'ì´ì•¼', 'ì•„ì•¼', 'aiya', 'aiya'
    ]
    
    for (const pattern of wakePatterns) {
      const idx = lower.indexOf(pattern)
      if (idx !== -1) {
        // ì›¨ì´í¬ ì›Œë“œ ì´í›„ í…ìŠ¤íŠ¸ ë°˜í™˜
        const afterWake = text.substring(idx + pattern.length).trim()
        return afterWake || 'ì•ˆë…•'  // ë¹ˆ ë¬¸ìì—´ì´ë©´ ê¸°ë³¸ ì¸ì‚¬
      }
    }
    return null
  }, [])

  useEffect(() => {
    const SpeechRecognition =
      (window as any).SpeechRecognition ||
      (window as any).webkitSpeechRecognition

    if (!SpeechRecognition) {
      setResponse('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•Šì•„ìš” ğŸ˜¢')
      return
    }

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = 'ko-KR'
    recognition.maxAlternatives = 3

    recognitionRef.current = recognition

    recognition.onresult = (event: any) => {
      let interimTranscript = ''
      let finalTranscript = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
          finalTranscript += transcript
        } else {
          interimTranscript += transcript
        }
      }

      const currentText = finalTranscript || interimTranscript
      if (currentText) {
        setLastHeard(currentText)
        console.log('[ë“¤ë¦¼]', currentText)
      }

      // ìµœì¢… ê²°ê³¼ì—ì„œ ì›¨ì´í¬ ì›Œë“œ ì²´í¬
      if (finalTranscript && !isProcessingRef.current) {
        const afterWake = checkWakeWord(finalTranscript)
        if (afterWake !== null) {
          console.log('[ì›¨ì´í¬ ì›Œë“œ ê°ì§€!]', finalTranscript, 'â†’', afterWake)
          callAPI(afterWake)
        }
      }
    }

    recognition.onerror = (event: any) => {
      console.log('[ìŒì„± ì¸ì‹ ì˜¤ë¥˜]', event.error)
      // ìë™ ì¬ì‹œì‘
      if (event.error !== 'not-allowed') {
        setTimeout(() => {
          try { recognition.start() } catch (e) {}
        }, 1000)
      }
    }

    recognition.onend = () => {
      console.log('[ìŒì„± ì¸ì‹ ì¢…ë£Œ, ì¬ì‹œì‘]')
      if (!isProcessingRef.current) {
        setTimeout(() => {
          try { recognition.start() } catch (e) {}
        }, 500)
      }
    }

    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ í›„ ì‹œì‘
    navigator.mediaDevices.getUserMedia({ audio: true })
      .then(() => {
        recognition.start()
        console.log('[ìŒì„± ì¸ì‹ ì‹œì‘]')
      })
      .catch((err) => {
        console.error('[ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€]', err)
        setResponse('ğŸ”’ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”')
      })

    return () => {
      try { recognition.stop() } catch (e) {}
    }
  }, [callAPI, checkWakeWord])

  return (
    <main className="flex flex-col items-center justify-center min-h-screen p-4 bg-gradient-to-b from-pink-200 via-purple-100 to-blue-200">
      {/* ë©”ì¸ */}
      <div className="text-center mb-8">
        <div className={`text-9xl mb-4 transition-all duration-300 ${isProcessing ? 'animate-pulse' : 'animate-bounce'}`}>
          {isProcessing ? 'ğŸ¤”' : 'ğŸ¤'}
        </div>
        <h1 className="text-5xl font-bold text-purple-800 mb-4">ì•„ì´ì•¼!</h1>
        <p className="text-2xl text-purple-600 font-semibold">
          {isProcessing ? 'ğŸ’­ ìƒê°í•˜ëŠ” ì¤‘...' : '"ì•„ì´ì•¼~" ë¼ê³  ë¶ˆëŸ¬ë´!'}
        </p>
      </div>

      {/* ë“¤ë¦° ë‚´ìš© í‘œì‹œ (ë””ë²„ê·¸ìš©) */}
      {lastHeard && !isProcessing && (
        <div className="mb-4 px-6 py-2 bg-gray-100 rounded-full text-gray-600 text-lg">
          ğŸ§ "{lastHeard}"
        </div>
      )}

      {/* ì‘ë‹µ */}
      {response && !isProcessing && (
        <div className="mt-4 p-8 bg-white rounded-3xl shadow-2xl max-w-md text-center">
          <p className="text-3xl text-gray-800 leading-relaxed font-bold">
            {response}
          </p>
        </div>
      )}

      {/* ë¡œë”© */}
      {isProcessing && (
        <div className="mt-8">
          <div className="animate-spin rounded-full h-16 w-16 border-4 border-purple-300 border-t-purple-600"></div>
        </div>
      )}

      {/* ìƒíƒœ í‘œì‹œ */}
      <div className="fixed bottom-4 left-4 right-4 flex justify-center">
        <div className={`px-6 py-3 rounded-full text-lg font-semibold shadow-lg ${
          isProcessing 
            ? 'bg-yellow-400 text-gray-800' 
            : 'bg-green-500 text-white'
        }`}>
          {isProcessing ? 'ğŸ’­ ìƒê° ì¤‘...' : 'ğŸ¤ ë“£ê³  ìˆì–´ìš”'}
        </div>
      </div>
    </main>
  )
}
