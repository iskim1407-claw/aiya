'use client'

import { useState, useRef, useEffect } from 'react'

interface RecordButtonProps {
  onAudioReady: (blob: Blob) => void
  isLoading?: boolean
}

// Web Speech API íƒ€ì…
declare global {
  interface Window {
    SpeechRecognition: any
    webkitSpeechRecognition: any
  }
}

export default function RecordButton({ onAudioReady, isLoading = false }: RecordButtonProps) {
  const [isRecording, setIsRecording] = useState(false)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const recognitionRef = useRef<any>(null)
  const [usingSpeechAPI, setUsingSpeechAPI] = useState(false)

  // Web Speech API ì„¤ì •
  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      if (SpeechRecognition) {
        recognitionRef.current = new SpeechRecognition()
        setUsingSpeechAPI(true)
        
        // í•œêµ­ì–´ ì„¤ì •
        recognitionRef.current.lang = 'ko-KR'
        recognitionRef.current.continuous = false
        recognitionRef.current.interimResults = false
        recognitionRef.current.maxAlternatives = 1
      }
    }
  }, [])

  const handleStart = async () => {
    setIsRecording(true)

    // Web Speech API ìš°ì„  ì‚¬ìš©
    if (usingSpeechAPI && recognitionRef.current) {
      try {
        recognitionRef.current.onstart = () => {
          console.log('[Speech API] ì¸ì‹ ì‹œì‘...')
        }

        recognitionRef.current.onresult = (event: any) => {
          const transcript = Array.from(event.results)
            .map((result: any) => result[0].transcript)
            .join('')
          
          console.log('[Speech API] ì¸ì‹ ì™„ë£Œ:', transcript)
          
          // í…ìŠ¤íŠ¸ë¥¼ Blobìœ¼ë¡œ ë³€í™˜í•´ì„œ ì „ì†¡ (ì„ì‹œ)
          // ì‹¤ì œë¡œëŠ” ë°”ë¡œ APIë¡œ ì „ì†¡
          sendText(transcript)
          setIsRecording(false)
        }

        recognitionRef.current.onerror = (event: any) => {
          console.error('[Speech API Error]', event.error)
          // í´ë°±: ë§ˆì´í¬ ë…¹ìŒ ì‚¬ìš©
          fallbackToAudioRecording()
        }

        recognitionRef.current.start()
      } catch (error) {
        console.error('Web Speech API ì˜¤ë¥˜:', error)
        fallbackToAudioRecording()
      }
    } else {
      fallbackToAudioRecording()
    }
  }

  const fallbackToAudioRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      streamRef.current = stream

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/wav',
      })
      mediaRecorderRef.current = mediaRecorder

      const chunks: BlobPart[] = []
      mediaRecorder.ondataavailable = (e) => chunks.push(e.data)
      mediaRecorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/wav' })
        onAudioReady(blob)
        stream.getTracks().forEach(track => track.stop())
        setIsRecording(false)
      }

      mediaRecorder.start()
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error)
      alert('ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”')
      setIsRecording(false)
    }
  }

  const handleStop = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
    }
    if (recognitionRef.current) {
      recognitionRef.current.stop()
    }
    setIsRecording(false)
  }

  // í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ APIë¡œ ì „ì†¡
  const sendText = async (text: string) => {
    try {
      const response = await fetch('/api/talk', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text, // í…ìŠ¤íŠ¸ ì§ì ‘ ì „ì†¡
          childId: 'default-child',
        }),
      })

      if (response.ok) {
        const data = await response.json()
        console.log('[API Response]', data)
        // ì‘ë‹µì„ ë°›ìœ¼ë©´ ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ê°€ ì²˜ë¦¬í•¨
        // (onAudioReady ì½œë°±ìœ¼ë¡œ ì „ë‹¬ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì£¼ì˜)
      }
    } catch (error) {
      console.error('[API Error]', error)
    }
  }

  return (
    <button
      onMouseDown={handleStart}
      onMouseUp={handleStop}
      onTouchStart={handleStart}
      onTouchEnd={handleStop}
      disabled={isLoading}
      className={`w-40 h-40 rounded-full text-5xl font-bold text-white shadow-2xl transition-all ${
        isRecording
          ? 'bg-gradient-to-br from-red-500 to-red-600 scale-110 animate-pulse'
          : 'bg-gradient-to-br from-blue-400 to-blue-600 hover:scale-110 active:scale-95'
      } ${
        isLoading ? 'opacity-50 cursor-not-allowed' : 'cursor-pointer'
      }`}
    >
      {isLoading ? 'â³' : 'ğŸ™ï¸'}
    </button>
  )
}
