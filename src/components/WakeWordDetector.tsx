'use client'

import { useEffect, useState, useRef, useCallback } from 'react'

interface WakeWordDetectorProps {
  onWakeWord: (text: string) => void
  isListening?: boolean
}

export default function WakeWordDetector({
  onWakeWord,
  isListening = true,
}: WakeWordDetectorProps) {
  const [status, setStatus] = useState('ðŸ”„ ì‹œìž‘ ì¤‘...')
  const [permissionGranted, setPermissionGranted] = useState(false)
  const [isActive, setIsActive] = useState(isListening)
  const recognitionRef = useRef<any>(null)
  const isProcessingRef = useRef(false)
  const restartTimeoutRef = useRef<NodeJS.Timeout | null>(null)

  // ì•ˆì •ì ì¸ ìž¬ì‹œìž‘ í•¨ìˆ˜
  const startRecognition = useCallback(() => {
    if (!recognitionRef.current || isProcessingRef.current) return
    
    try {
      recognitionRef.current.start()
    } catch (e) {
      // ì´ë¯¸ ì‹œìž‘ëœ ê²½ìš° ë¬´ì‹œ
      console.log('[Recognition] Already started or error:', e)
    }
  }, [])

  // ì§€ì—° ìž¬ì‹œìž‘ (ì¤‘ë³µ ë°©ì§€)
  const scheduleRestart = useCallback((delayMs: number = 1000) => {
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current)
    }
    restartTimeoutRef.current = setTimeout(() => {
      if (isActive && !isProcessingRef.current) {
        startRecognition()
      }
    }, delayMs)
  }, [isActive, startRecognition])

  // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
  useEffect(() => {
    async function requestMicPermission() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        stream.getTracks().forEach(track => track.stop())
        setPermissionGranted(true)
        setStatus('ðŸŽ¤ ë“£ê³  ìžˆì–´ìš”...')
      } catch (err) {
        console.error('ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€:', err)
        setStatus('ðŸ”’ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”')
        setPermissionGranted(false)
      }
    }
    requestMicPermission()
  }, [])

  useEffect(() => {
    if (!isActive || !permissionGranted) return

    const SpeechRecognition =
      (window as any).SpeechRecognition ||
      (window as any).webkitSpeechRecognition

    if (!SpeechRecognition) {
      setStatus('âŒ ìŒì„± ì¸ì‹ ë¯¸ì§€ì›')
      return
    }

    const recognition = new SpeechRecognition()
    recognition.continuous = false  // ëª¨ë°”ì¼ ì•ˆì •ì„±ì„ ìœ„í•´ false
    recognition.interimResults = true  // ì¤‘ê°„ ê²°ê³¼ë„ ë°›ê¸°
    recognition.lang = 'ko-KR'
    recognition.maxAlternatives = 1

    recognitionRef.current = recognition

    recognition.onstart = () => {
      setStatus('ðŸŽ¤ ë“£ê³  ìžˆì–´ìš”...')
    }

    recognition.onresult = (event: any) => {
      let transcript = ''
      let isFinal = false

      for (let i = event.resultIndex; i < event.results.length; i++) {
        transcript += event.results[i][0].transcript
        if (event.results[i].isFinal) {
          isFinal = true
        }
      }

      // ì›¨ì´í¬ ì›Œë“œ ê°ì§€
      const lowerTranscript = transcript.toLowerCase().trim()
      const wakeWords = ['ì•„ì´ì•¼', 'ì•„ì´ì•¼!', 'ì•„ì´ì•¼~', 'ì•„ì´ì–Œ', 'ì•„ì´ì•„', 'aiya', 'ai ya']

      if (wakeWords.some((w) => lowerTranscript.includes(w))) {
        console.log('[ì›¨ì´í¬ ì›Œë“œ ê°ì§€]', transcript)
        isProcessingRef.current = true
        setStatus('âœ… ë“¤ì—ˆì–´! ë§í•´ë´~')
        
        // í˜„ìž¬ ì¸ì‹ ì¤‘ì§€
        try {
          recognition.stop()
        } catch (e) {}

        // ì›¨ì´í¬ ì›Œë“œ ì´í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        let afterWakeWord = transcript
        for (const w of wakeWords) {
          const idx = lowerTranscript.indexOf(w)
          if (idx !== -1) {
            afterWakeWord = transcript.substring(idx + w.length).trim()
            break
          }
        }

        // ì›¨ì´í¬ ì›Œë“œ í›„ ì¶”ê°€ ìŒì„± ìž…ë ¥ ë°›ê¸°
        setTimeout(() => {
          const listeningRecognition = new SpeechRecognition()
          listeningRecognition.continuous = false
          listeningRecognition.interimResults = false
          listeningRecognition.lang = 'ko-KR'

          let finalText = afterWakeWord

          listeningRecognition.onstart = () => {
            setStatus('ðŸŽ¤ ë“£ê³  ìžˆì–´ìš”...')
          }

          listeningRecognition.onresult = (e: any) => {
            for (let i = 0; i < e.results.length; i++) {
              finalText += ' ' + e.results[i][0].transcript
            }
            finalText = finalText.trim()
          }

          listeningRecognition.onerror = (e: any) => {
            console.log('[ë“£ê¸° ì˜¤ë¥˜]', e.error)
          }

          listeningRecognition.onend = () => {
            console.log('[ìŒì„± ìž…ë ¥ ì™„ë£Œ]', finalText)
            
            if (finalText) {
              setStatus('ðŸ’­ ìƒê° ì¤‘...')
              onWakeWord(finalText)
            } else {
              setStatus('ðŸŽ¤ ë“£ê³  ìžˆì–´ìš”...')
            }
            
            // ì²˜ë¦¬ ì™„ë£Œ í›„ ë©”ì¸ ì¸ì‹ ìž¬ì‹œìž‘
            isProcessingRef.current = false
            scheduleRestart(1500)
          }

          try {
            listeningRecognition.start()
          } catch (e) {
            console.error('[ë“£ê¸° ì‹œìž‘ ì‹¤íŒ¨]', e)
            isProcessingRef.current = false
            scheduleRestart(1000)
          }
        }, 300)

        return
      }

      // ì›¨ì´í¬ ì›Œë“œ ì—†ìœ¼ë©´ ê³„ì† ë“£ê¸°
      if (isFinal && !wakeWords.some((w) => lowerTranscript.includes(w))) {
        console.log('[ì¼ë°˜ ìŒì„±]', transcript)
      }
    }

    recognition.onerror = (event: any) => {
      console.log('[ì¸ì‹ ì˜¤ë¥˜]', event.error)
      
      if (event.error === 'not-allowed') {
        setStatus('ðŸ”’ ë§ˆì´í¬ ê¶Œí•œ í•„ìš”')
        return
      }
      
      if (event.error === 'no-speech') {
        setStatus('ðŸŽ¤ ë“£ê³  ìžˆì–´ìš”...')
        scheduleRestart(500)
        return
      }

      setStatus('âš ï¸ ë‹¤ì‹œ ì‹œë„ ì¤‘...')
      scheduleRestart(2000)
    }

    recognition.onend = () => {
      if (!isProcessingRef.current && isActive) {
        scheduleRestart(800)
      }
    }

    // ì´ˆê¸° ì‹œìž‘
    startRecognition()

    return () => {
      if (restartTimeoutRef.current) {
        clearTimeout(restartTimeoutRef.current)
      }
      try {
        recognition.stop()
      } catch (e) {}
    }
  }, [isActive, permissionGranted, onWakeWord, scheduleRestart, startRecognition])

  return (
    <div className="fixed bottom-4 left-4 bg-gradient-to-r from-blue-500 to-purple-500 text-white px-5 py-3 rounded-full text-lg font-semibold shadow-lg">
      {status}
    </div>
  )
}
